# Configuration file for the image classification application
#
# Date: September 2018
# Author: Ignacio Heredia
# Email: iheredia@ifca.unican.es
# Github: ignacioheredia
#
# References
# ----------
# https://pyyaml.org/wiki/PyYAMLDocumentation


#####################################################
# Options for general configuration
#####################################################

general:

  base_directory:
    value: "."
    type: "str"
    help: >
          Base directory for data and models. All the data that will be read and written will be done within this
          directory.
          If path is relative it will be appended to the package path.

  dataset_directory:
    value: "data/audios"
    type: "str"
    help: >
          Base directory for audio files. If the path is relative, it will be appended to the package path.
          If the directory contains the embeddings (.npy files) instead, please remember to set all preprocessing
          to False.


#####################################################
#  Options to customize the model
#####################################################

model:

  num_classes:
    value:
    type: "int"
    range: [1, None]
    help: >
          Total number of possible output classes. If not provided, we will use the max label number from y_train.


#####################################################
#  Options for preprocessing
#####################################################

preprocessing:

  files_to_PCM:
    value: True
    type: "bool"
    help: >
          Whether to transform the files to 16-bit PCM wav files. You can disable this option if your files are already
          in that format.

  compute_embeddings:
    value: True
    type: "bool"
    help: >
          Whether to compute the embeddings. You can disable this option if you already have computed the embeddings.
          If you disable this option then the paths in your `train.txt`and `val.txt` should point to the `.npy`
          embedding files. And `dataset_directory` should point to the directory containing the embeddings.


#####################################################
#  Options about your training routine
#####################################################

training:

  mode:
    value: "normal"
    type: "str"
    choices: ['normal', 'fast']
    help: >
      Mode for the training routine. In the `fast` mode we do not training the lower layers convolutional layers and
      only train the upper dense layer. The gain in training speed (~25% faster?) comes at the cost of a somewhat lower
      accuracy, because the weights of the convolutional layers will be the ones from the Imagenet pretraining and thus
      not finetuned to our dataset.

  initial_lr:
    value: 0.001
    type: "float"
    help: >
          Initial learning rate.

  batch_size:
    value: 500
    type: "int"
    range: [1, 10000]
    help: >
          Batchsize to use during training. If your model has a large number of classes (>1000) you might need to decrease
          your batchsize so that the model still fits in the GPU.

  epochs:
    value: 15
    type: "int"
    range: [0, None]
    help: >
          Number of epochs to use for training.

  ckpt_freq:
    value:
    type: "float"
    range: [0, 1]
    help: >
          Frequency of the checkpoints (Float between 0 and 1). If None there will be no checkpoints saved. If 0.0 there
          will be 1 checkpoint per epoch. For example 0.1 means there will be 10 ckpts during the training.

  lr_schedule_mode:
    value: "step"
    type: "str"
    choices: ['step']
    help: >
          Mode for the learning rate schedule computation.

  lr_step_decay:
    value: 0.1
    type: "float"
    range: [0, 1]
    help: >
          Amount to decay the lr. Only relevant if lr_schedule_mode is set to 'step'

  lr_step_schedule:
    value: [0.7, 0.9]
    type: "list"
    item_type: float
    help: >
          List of the fraction of the total time at which apply a decay. For example [0.7, 0.9] means that the lr
          will be decay at 70% and 90% of total number of epochs.

  l2_reg:
    value: 0.0001
    type: "float"
    help: >
          L2 regularizer for the two last Dense layers.

  use_validation:
    value: True
    type: "bool"
    help: >
          Whether to use or not validation. If True you have to provide a `val.txt` file in the `splits` directory.

  use_early_stopping:
    value: False
    type: "bool"
    help: >
          Whether to use or not early stopping. If True you have to provide a `val.txt` file in the `splits` directory.

  use_multiprocessing:
    value: True
    type: "bool"
    help: >
          Whether to use or not multiple workers to do preprocess data (ie. do data augmentation)
          faster during training. Disable it if your computing resources are scarce.

#####################################################
#  Options about monitoring your training
#####################################################

monitor:

  use_tensorboard:
    value: True
    type: "bool"
    help: >
          Use tensorboard to visualize the relevant metrics during the training process.

  use_remote:
    value: False
    type: "bool"
    help: >
          Forward the logs through a defined port if executing in a remote machine.

#####################################################
#  Options to test your model
#####################################################

testing:

  timestamp:
    value:
    type: "str"
    help: >
      Model timestamp to use for prediction.

  ckpt_name:
    value: "final_model.h5"
    type: "str"
    help: >
      Checkpoint inside the timestamp to use for prediction.
